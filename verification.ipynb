{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10416d8ed5597a6c",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-30T00:38:13.792932213Z",
     "start_time": "2023-11-30T00:38:13.629297349Z"
    }
   },
   "outputs": [],
   "source": [
    "from maraboupy import Marabou, MarabouCore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def write_values_to_csv(values_dict, filename):\n",
    "    # 获取当前脚本的目录\n",
    "    current_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "    # 将文件名与当前目录连接起来\n",
    "    full_path = os.path.join(current_directory, filename)\n",
    "\n",
    "    # 打开文件进行追加\n",
    "    with open(full_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # 提取字典中的值并写入一行\n",
    "        values = list(values_dict.values())\n",
    "        writer.writerow(values)\n",
    "\n",
    "    print(f\"Values written to {full_path}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T00:38:15.587617685Z",
     "start_time": "2023-11-30T00:38:15.562874501Z"
    }
   },
   "id": "812ff60b0936ace3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    time = 0\n",
    "    count = 0\n",
    "    # data = pd.read_csv(r'C:\\Users\\shinm\\OneDrive - University of Bristol\\Courses\\DissertationProject\\Experiment\\Code\\Marabou\\Data_STS_modified.csv')\n",
    "    data = pd.read_csv(\n",
    "        r'/home/adam/Experiment/Code/Marabou/Data_STS_modified.csv')\n",
    "    # Names\n",
    "    names = open(\n",
    "        \"/home/adam/Experiment/Datasets/STS_data/Processing/Data_Names.txt\", \"r\")\n",
    "    # names = open(\"C:\\\\Users\\\\shinm\\\\OneDrive - University of Bristol\\\\Courses\\\\DissertationProject\\\\Experiment\\\\Datasets\\\\STS_data\\\\Processing\\\\Data_Names.txt\", \"r\")\n",
    "\n",
    "    # names = open(\"Data_Names_Gender.txt\", \"r\")\n",
    "    contents = names.read()\n",
    "    dictionary = ['Stand-to-stand time', 'Sit-to-stand time', 'Stand-to-sit time', 'M_hip vertical range', 'M_hip depth range', 'M_hip max vertical velocity',\n",
    "                  'M_hip min vertical velocity', 'M_hip max depth velocity', 'M_hip min depth velocity', 'Knee flexo-extension range', 'Knee flexo-extension max velocity', 'Knee flexo-extension min velocity',\n",
    "                  'Hip flexo-extension range', 'Hip flexo-extension max velocity', 'Hip flexo-extension min velocity', 'Hip abduction-adduction range', 'Hip abduction-adduction max velocity', 'Hip abduction-adduction min velocity',\n",
    "                  'Ankle flexo-extension range', 'Ankle flexo-extension max velocity', 'Ankle flexo-extension min velocity', 'M_shoulder vertical range', 'M_shoulder depth range', 'M_shoulder max vertical velocity',\n",
    "                  'M_shoulder min vertical velocity', 'M_shoulder max depth velocity', 'Spine flexo-extension range', 'Spine flexo-extension max velocity', 'Spine flexo-extension min velocity', 'Spine abduction-adduction range',\n",
    "                  'Spine abduction-adduction max velocity', 'Spine abduction-adduction min velocity', 'Heart Rate']\n",
    "    data.columns = ['Stand-to-stand time', 'Sit-to-stand time', 'Stand-to-sit time',\n",
    "                    'M_hip vertical range', 'M_hip depth range', 'M_hip max vertical velocity',\n",
    "                    'M_hip min vertical velocity', 'M_hip max depth velocity', 'M_hip min depth velocity',\n",
    "                    'Knee flexo-extension range', 'Knee flexo-extension max velocity', 'Knee flexo-extension min velocity',\n",
    "                    'Hip flexo-extension range', 'Hip flexo-extension max velocity', 'Hip flexo-extension min velocity',\n",
    "                    'Hip abduction-adduction range', 'Hip abduction-adduction max velocity', 'Hip abduction-adduction min velocity',\n",
    "                    'Ankle flexo-extension range', 'Ankle flexo-extension max velocity', 'Ankle flexo-extension min velocity',\n",
    "                    'M_shoulder vertical range', 'M_shoulder depth range', 'M_shoulder max vertical velocity',\n",
    "                    'M_shoulder min vertical velocity', 'M_shoulder max depth velocity', 'Spine flexo-extension range',\n",
    "                    'Spine flexo-extension max velocity', 'Spine flexo-extension min velocity', 'Spine abduction-adduction range',\n",
    "                    'Spine abduction-adduction max velocity', 'Spine abduction-adduction min velocity', 'Heart Rate',\n",
    "                    'Fatigue Condition']\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    data = data.drop(columns=['M_hip depth range', 'M_hip min vertical velocity', 'M_hip max depth velocity', 'M_hip min depth velocity',\n",
    "                              'Knee flexo-extension min velocity', 'Hip flexo-extension min velocity',\n",
    "                              'Hip abduction-adduction min velocity', 'Ankle flexo-extension min velocity',\n",
    "                              'M_shoulder depth range', 'M_shoulder min vertical velocity',\n",
    "                              'M_shoulder max depth velocity', 'Spine flexo-extension min velocity',\n",
    "                              'Spine abduction-adduction min velocity'])\n",
    "\n",
    "    # bounds = pd.read_csv(\n",
    "    #     '/Code/Marabou/Behaviour_analysis_misclassification/bounds_3std.csv')\n",
    "    # bounds = pd.read_csv(\n",
    "    #     '/home/adam/Experiment/Code/Marabou/Behaviour_analysis_misclassification/bounds_fuzz90.csv'\n",
    "    # )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89d65f4c49df1a0b"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "file_name = 'exo_model_without_softmax'\n",
    "network = Marabou.read_tf(file_name, modelType='savedModel_v2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T00:38:22.106359292Z",
     "start_time": "2023-11-30T00:38:21.849459873Z"
    }
   },
   "id": "64717ea26889631f"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# bounds = pd.read_csv(\n",
    "#     '/home/adam/Experiment/Code/Marabou/Behaviour_analysis_misclassification/Bounds/HR-STS/bounds_mixed_inputspacetop90.csv'\n",
    "#     )\n",
    "# high_fatigue = pd.DataFrame(bounds)\n",
    "\n",
    "file_name = 'model_without_softmax.onnx'\n",
    "# network = Marabou.read_onnx(file_name, inputNames='dense_0_input', outputNames='dense_62', reindexOutputVars=True)\n",
    "network = Marabou.read_onnx(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T00:38:32.056945179Z",
     "start_time": "2023-11-30T00:38:31.838753441Z"
    }
   },
   "id": "bcf72b1c839ab72d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# High fatigue query\n",
    "inputVars = network.inputVars[0][0]\n",
    "\n",
    "# Set the upper bound of each input variable to the high_fatigue upper bound\n",
    "for i, (var_name, bounds) in enumerate(high_fatigue.iterrows()):\n",
    "    network.setUpperBound(inputVars[i], bounds['upper_bound'])\n",
    "    network.setLowerBound(inputVars[i], bounds['lower_bound'])\n",
    "\n",
    "# Set the lower and upper bounds for the output variable(0-6 means low or medium fatigue)\n",
    "outputVars = network.outputVars[0]\n",
    "for i in range(len(outputVars)):\n",
    "    for j in range(len(outputVars[i])):\n",
    "        network.setLowerBound(outputVars[i][j], 0)\n",
    "        network.setUpperBound(outputVars[i][j], 6)\n",
    "\n",
    "options = Marabou.createOptions(numWorkers=20, initialTimeout=5, initialSplits=100, onlineSplits=100,\n",
    "                                timeoutInSeconds=1800, timeoutFactor=1.5,\n",
    "                                verbosity=2, snc=True, splittingStrategy='auto',\n",
    "                                sncSplittingStrategy='auto', restoreTreeStates=False,\n",
    "                                splitThreshold=20, solveWithMILP=False, dumpBounds=True)\n",
    "# Execute query in a loop\n",
    "try:\n",
    "\n",
    "    while True:\n",
    "        result = network.solve(\n",
    "            filename='/home/adam/Experiment/Code/Marabou/logs/Behviour_analysis_mixedtop90.log',\n",
    "            options=options)\n",
    "        status, values, stats = result\n",
    "        write_values_to_csv(values, 'HR-STSmixed_results/highfatigue_mixedtop90_005.csv')\n",
    "        time += stats.getTotalTimeInMicro()\n",
    "        count += 1\n",
    "\n",
    "        # if time > 180000000:\n",
    "        #     print(\"Timeout.\")\n",
    "        #     print(\"Time:\", time)\n",
    "        #     break\n",
    "\n",
    "        # If return 'sat', which means there are some high fatigue data in the dataset is classified as low or medium fatigue\n",
    "        if status == \"sat\":\n",
    "            print(\"Solution: \", count, \" found!\")\n",
    "            # print(\"Values:\", values)\n",
    "\n",
    "            print(\"Time:\", time)\n",
    "\n",
    "            # If result is SAT, add a new constraint to exclude the current solution\n",
    "            for i in range(len(inputVars)):\n",
    "                # Create a constraint that the variable is less than the current solution\n",
    "                eq1 = MarabouCore.Equation(MarabouCore.Equation.LE)\n",
    "                eq1.addAddend(1, inputVars[i])\n",
    "                # Subtract a small value to avoid the current solution\n",
    "                eq1.setScalar(values[inputVars[i].item()] - 0.05)\n",
    "\n",
    "                # Create a constraint that the variable is greater than the current solution\n",
    "                eq2 = MarabouCore.Equation(MarabouCore.Equation.GE)\n",
    "                eq2.addAddend(1, inputVars[i])\n",
    "                # Add a small value to avoid the current solution\n",
    "                eq2.setScalar(values[inputVars[i].item()] + 0.05)\n",
    "\n",
    "                # Add the disjunction of the two constraints to the network\n",
    "                network.addDisjunctionConstraint([[eq1], [eq2]])\n",
    "\n",
    "        elif status == \"unsat\":\n",
    "            print(\"No solution found.\")\n",
    "            print(\"Time:\", time)\n",
    "            break\n",
    "\n",
    "        pass\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted\")\n",
    "    sys.exit()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
