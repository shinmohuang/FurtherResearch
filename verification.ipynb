{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from maraboupy import Marabou, MarabouCore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import sys"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93ebcfc2e228a4b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_values_to_csv(values_dict, filename):\n",
    "    \"\"\"\n",
    "    Write the values from a dictionary into a CSV file.\n",
    "\n",
    "    Args:\n",
    "    values_dict (dict): A dictionary containing the values to be written into the CSV file.\n",
    "    filename (str): The name of the CSV file to write into.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    >>> values_dict = {'name': 'John', 'age': 30, 'city': 'New York'}\n",
    "    >>> filename = 'data.csv'\n",
    "    >>> write_values_to_csv(values_dict, filename)\n",
    "    Values written to /home/adam/FurtherResearch/data.csv\n",
    "    \"\"\"\n",
    "    # Get the directory of the current script\n",
    "    current_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "    # Join the filename with the current directory\n",
    "    full_path = os.path.join(current_directory, filename)\n",
    "\n",
    "    # Open the file for appending\n",
    "    with open(full_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Extract the values from the dictionary and write them into a row\n",
    "        values = list(values_dict.values())\n",
    "        writer.writerow(values)\n",
    "\n",
    "    print(f\"Values written to {full_path}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "904b1512867a35a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "file_name = 'model_without_softmax.onnx'\n",
    "network = Marabou.read_onnx(file_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4854a8ed5b3916c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the input and output variables\n",
    "inputVars = network.inputVars[0][0]\n",
    "outputVars = network.outputVars[0]\n",
    "\n",
    "# Define the indices for the fatigue levels\n",
    "low_fatigue_idx = 0\n",
    "medium_fatigue_idx = 1\n",
    "high_fatigue_idx = 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebe2ad777aeb5db2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the high fatigue statistics\n",
    "high_fatigue = pd.read_csv('statistic_analysis/dataset_statistics_fatigue_level_2.csv')\n",
    "mean_values = high_fatigue['mean'][:-1].values\n",
    "\n",
    "# Define the initial input range (a small range centered around the mean)\n",
    "initial_range= [0.01] * 63  # Initial range\n",
    "step_size = high_fatigue['std'][:-1].values * 0.1      # The range to increase at each iteration\n",
    "\n",
    "# Create the options for the Marabou solver\n",
    "options = Marabou.createOptions(numWorkers=20, initialTimeout=5, initialSplits=100, onlineSplits=100,\n",
    "                                    timeoutInSeconds=1800, timeoutFactor=1.5,\n",
    "                                    verbosity=2, snc=True, splittingStrategy='auto',\n",
    "                                    sncSplittingStrategy='auto', restoreTreeStates=False,\n",
    "                                    splitThreshold=20, solveWithMILP=True, dumpBounds=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "311134b39259e531"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The iterative process\n",
    "unsat = True\n",
    "while unsat:\n",
    "    # Reset the network\n",
    "    network = Marabou.read_onnx(file_name)\n",
    "\n",
    "    # Set the input range\n",
    "    for i, mean_val in enumerate(mean_values):\n",
    "        network.setLowerBound(inputVars[i], mean_val - initial_range[i])\n",
    "        network.setUpperBound(inputVars[i], mean_val + initial_range[i])\n",
    "\n",
    "    # Define the output condition\n",
    "    desired_output_class = 2  # High fatigue class index\n",
    "    for i in range(len(outputVars)):\n",
    "        if i != desired_output_class:\n",
    "            network.addInequality([outputVars[0][i], outputVars[0][desired_output_class]], [1, -1], 0)\n",
    "\n",
    "    # Run the verification\n",
    "    vals = network.solve(verbose=True,options=options)[0]\n",
    "\n",
    "    # Check the result\n",
    "    if vals == \"unsat\":\n",
    "        # If it is UNSAT, increase the input range\n",
    "        for i in range(len(initial_range)):\n",
    "            initial_range[i] += step_size[i]\n",
    "    else:\n",
    "        # If it is not UNSAT, stop the iteration\n",
    "        unsat = False\n",
    "\n",
    "# Print the minimum UNSAT range\n",
    "print(f\"Minimum UNSAT range: {initial_range - step_size}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4303df0a5586231"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
